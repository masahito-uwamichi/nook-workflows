
# [R] Transformers without Normalization (FAIR Meta, New York University, MIT, Princeton University)

**Upvotes**: 207



[View on Reddit](https://www.reddit.com/r/MachineLearning/comments/1jbs7xg/r_transformers_without_normalization_fair_meta/)

1. **ポストの内容の説明**

このRedditのポストは、論文「Transformers without Normalization」を紹介するものです。この論文では、Transformerモデルにおいて、従来必須と考えられていたNormalizationレイヤーを、新しい要素ごとの演算であるDynamic Tanh (DyT) で置き換えることで、同等またはそれ以上の性能を達成できることを示しています。

*   **背景:** 近年のニューラルネットワークではNormalizationレイヤーが広く使用されており、その重要性が認識されていました。
*   **提案手法:** 論文では、DyT(x) = tanh(αx) という関数をNormalizationレイヤーの代替として使用することを提案しています。DyTは、TransformerのNormalizationレイヤーがtanh関数に似た入出力マッピングを生成するという観察に基づいています。
*   **結果:** DyTを組み込んだTransformerモデルは、Normalizationレイヤーを使用したモデルと同等またはそれ以上の性能を発揮し、ハイパーパラメータの調整もほとんど必要ありません。様々なタスク (画像認識、生成、教師あり学習、自己教師あり学習、コンピュータビジョン、言語モデル) でDyTの有効性が検証されています。
*   **主張:** この研究は、Normalizationレイヤーがニューラルネットワークに不可欠であるという従来の考え方に疑問を投げかけ、Normalizationレイヤーの役割に関する新しい洞察を提供します。
*   **その他:** 論文のコードとウェブサイトへのリンク、および論文著者の一人であるZhuang LiuによるX (旧Twitter) での詳細なスレッドへのリンクが提供されています。

2. **特に興味深いコメント**

以下のコメントが特に興味深いと思われます。

*   **「I'm training a ViT right now with it. (Not supervised classification like paper, but closer to dino algorithm). Training is actually a bit slower, probably because I'm not fusing the ops. Quality is on par, maybe 1% worse. I'm happily surprised. Replacing a reduction with a pointwise operation is amazing for fusion.」**

    *   このコメントは、実際にDyTをVision Transformer (ViT) に適用しているユーザーからの報告です。
    *   論文と同様の教師あり分類タスクではなく、DINOアルゴリズムに近い自己教師あり学習で使用している点が興味深いです。
    *   トレーニング速度がわずかに遅いものの、性能はほぼ同等 (1%程度の低下) であるという結果は、DyTの潜在的な実用性を示唆しています。
    *   また、reduction演算をpointwise演算に置き換えることで、演算の融合 (fusion) が容易になるという指摘は、実装上の利点を示唆しています。

*   **「What I think this is actually doing is separating feature transformation from feature aggregation. CNNs have gone through a similar development with depthwise separable convolutions.」**

    *   このコメントは、DyTの動作原理に関する洞察を提供しています。
    *   DyTが特徴変換と特徴集約を分離する役割を果たしている可能性を指摘し、CNNにおけるdepthwise separable convolutionとの類似性を指摘しています。
    *   この視点は、DyTの有効性をより深く理解するための手がかりとなる可能性があります。

*   **「I find sigmoids and tanh still fascinating, and I think the vanishing gradients are a problem of bad initializations, but I am not fully convinced of the trick here.  It is interesting but sounds like trivia, even though it's authored by both Kaiming He and Yann LeCun. What is missing is a thorough analysis on how convenient DyT is depending on token counts, paradoxically I'm interested in small scale Transformers and I don't see a strong theoretical reason for "simplifying" nets by putting the element-wise tanh instead of per-token standardization. Also the evidence for sigmoid input-output relationship is just a couple layers in a couple models, it's fine if the supplementaries extend it. The Normalized Transformer sounded stronger. EDIT: I mean nGPT, the Transformer with Normalized activations to stay on the hypersphere of feature space」**

    *   Normalizationレイヤーの代替というアイデア自体に懐疑的な意見を述べています。
    *   DyTの有効性がトークン数に依存する可能性がある点を指摘し、小規模なTransformerにおける利用に関心を示しています。
    *   DyTの理論的な根拠や、tanh関数を使用することの利点について疑問を呈しています。
    *   入出力関係がsigmoid関数に似ているという根拠が不十分であると指摘しています。
    *   他の正規化手法（nGPT）の方が優れている可能性を示唆しています。
    *   このコメントは、論文の限界や今後の研究の方向性を示唆しており、批判的な視点を提供しています。


---

# [D] The Cultural Divide between Mathematics and AI

**Upvotes**: 33



[View on Reddit](https://www.reddit.com/r/MachineLearning/comments/1jby0cz/d_the_cultural_divide_between_mathematics_and_ai/)

はい、承知いたしました。以下に順を追って詳細に、分かりやすく回答します。

**1. ポストの内容**

このRedditポストのタイトルは「[D] MathematicsとAIの間の文化的な隔たり」であり、数学と人工知能（AI）の分野における考え方やアプローチの違いについて議論していることが伺えます。投稿自体は共有された記事か、または問題提起の可能性があります（タイトルに[D]とあることからディスカッションを促していると考えられます）。コメントの内容から察するに、AI研究における数学の役割や、数学者とAI研究者の間の連携の現状などが主なテーマとして扱われているようです。

**2. 特に興味深いコメント**

以下の2つのコメントが特に興味深いと考えられます。

*   **4 upvotesのコメント：** このコメントは、AIで使用される数学が、マックスウェル方程式のような深く根本的な物理数学ではなく、どちらかというと「エンジニアリング」数学であると指摘しています。AI分野がまだ新しく実験的な段階であり、複雑な数学を使うよりも、うまくいったこと、うまくいかなかったことを記述する方が良い場合もあると主張しています。また、AI、機械学習（ML）、深層学習（DL）、強化学習（RL）を工学的な分野として捉えることを推奨しています。さらに、数学者が論文で過剰に数学を使いすぎる傾向があるのではないかという疑問を呈し、もっとコードを重視すべきだと述べています。

    *   **理由:** このコメントは、AI研究における数学の役割について具体的な問題提起をしており、数学者とAI研究者の間での視点の違いを浮き彫りにしています。実用性を重視するAIエンジニアリングの視点から、現在のAI研究のあり方に疑問を投げかけている点が興味深いです。

*   **10 upvotesのコメント：** このコメントは、数学者がAIモデルを「ブラックボックス」から解放し、説明可能にするという主張に対して懐疑的な見方を示しています。数学者がAI *を* 数学のために活用したり、新しいアルゴリズムの発見に貢献したりすることにもっと注力すべきだと提案しています。拡散モデルのような、より数学的な手法に数学者からの貢献が少ないことを残念に思っている点も指摘しています。

    *   **理由:** このコメントは、数学者がAI研究にどのように貢献できるかという具体的な方向性を示唆しており、建設的な議論を促す内容になっています。数学の知識をAIの説明可能性やアルゴリズムの発見に活用するという提案は、今後の数学とAIの連携の可能性を示唆しており、非常に興味深いです。


---

# [R] Recent advances in recurrent neural networks---any sleepers?

**Upvotes**: 20



[View on Reddit](https://www.reddit.com/r/MachineLearning/comments/1jbzcoc/r_recent_advances_in_recurrent_neural_networksany/)

はい、承知いたしました。以下に、ご質問への回答を順を追って詳細に説明します。

**1. このポストの内容**

このRedditポストは、再帰型ニューラルネットワーク（RNN）の最近の進歩、特に「隠れた存在」（sleeper：注目されていないが潜在能力のあるもの）について議論しています。

*   **投稿タイトルと投稿文:** 投稿者は、最近のRNNの話題としてMambaばかりが注目されていることに言及し、他の有望なRNNフレームワークはないかと問いかけています。つまり、Mamba以外で、RNNの分野で潜在的な可能性を秘めているにもかかわらず、あまり注目されていない技術やアーキテクチャはないか、情報提供を求めています。

*   **全体的なテーマ:** RNNは、自然言語処理（NLP）などの分野で広く使用されているニューラルネットワークの一種です。しかし、近年ではTransformerアーキテクチャが台頭し、RNNの存在感は薄れてきています。この投稿は、Transformer全盛の時代において、RNNの分野でまだ注目すべき進歩や可能性がないかを探るものです。

**2. このポストに対するコメントのうち、特に興味深いもの**

コメントの中で特に興味深いのは、以下の2点です。

*   **ゲート付きデルタネット（Gated Deltanet）のバリエーション（例：RWKV v7）:** このコメントは、データに依存した状態減衰と学習率の更新を行うゲート付きデルタネットのバリエーション（例：RWKV v7）に注目しています。特に、Test Time Regressionフレームワークの論文の引用を追うことを勧めています。これは、Mambaほど注目されていなくても、RNNの潜在的な代替アーキテクチャを示唆している点で興味深いです。

*   **Transformerとの比較と限界:** このコメントは、MambaがTransformerの唯一の代替として注目されているものの、Transformerを超える可能性は低いと指摘しています。Transformerの引用数と、他のRNNアーキテクチャ（RetNet、xLSTM、Titanなど）の引用数を比較することで、Transformerの圧倒的な優位性を示しています。さらに、Transformerがすべてのトークンに同時に注意を払い、忘れることがないという理論上の優位性を指摘し、大規模なデータと計算資源を投入する傾向がTransformerのさらなる優位性を生むことを示唆しています。Meta、Elon Musk、Microsoftの事例を引用して、この傾向を裏付けています。このコメントは、RNNの現状と課題を明確に示しており、非常に洞察に満ちています。

これらのコメントは、RNNの分野における最新の動向と、Transformerとの競争における課題を理解する上で非常に役立ちます。また、Mamba以外の有望なRNNアーキテクチャや研究の方向性を示唆している点も興味深いです。


---

# [R] 4D Language Fields for Dynamic Scenes via MLLM-Guided Object-wise Video Captioning

**Upvotes**: 1



[View on Reddit](https://www.reddit.com/r/MachineLearning/comments/1jcfw3p/r_4d_language_fields_for_dynamic_scenes_via/)

1. **ポストの内容の説明**

このRedditの投稿は、最新の研究論文「4D LangSplat」について解説しています。この論文は、動的な3Dシーン（時間とともに変化する3D環境）において、言語理解を可能にする新しい技術を提案しています。

具体的には、以下の点が重要です。

*   **4D Gaussian Splattingの利用:** 動的な3Dシーンを効率的に再構築するために、4D Gaussian Splattingという技術を使用しています。これは、3D空間内の点（ガウス分布）を使ってシーンを表現し、時間の経過とともにそれらの点の位置や形状を変化させることで、動きを表現するものです。

*   **マルチモーダルLLM（大規模言語モデル）との統合:** シーン内のオブジェクトやアクションを言語で理解するために、マルチモーダルLLM（GPT-4Vなど）を使用しています。LLMは、画像や動画などの視覚情報とテキスト情報を同時に処理できるため、シーンの内容を言語で記述したり、質問に答えたりすることができます。

*   **言語と3Dシーンの関連付け:** LLMを使って、3Dシーン内の各点（Gaussian）に言語的な特徴を付与します。これにより、言語クエリ（質問や指示）を3Dシーン内の特定のオブジェクトやアクションに関連付けることができます。

*   **ゼロショット能力:** 新しい動画に対して、追加のトレーニングなしで動作します。これは、事前に学習したLLMの知識を活用することで、新しいシーンでもすぐに言語理解が可能になることを意味します。

この技術によって、以下のことが可能になります。

*   **時間的なオブジェクトの参照:** 時間の経過とともに変化するシーン内で、特定のオブジェクトを言語的に追跡できます。（例：「赤い車はどこに移動しましたか？」）

*   **動的なシーンの説明:** 特定の瞬間に何が起こっているかを説明できます。（例：「5秒後に何が起きますか？」）

*   **クエリベースの推論:** オブジェクトの関係やアクションに関する質問に答えることができます。（例：「青い箱は赤い箱の隣にありますか？」）

*   **視点の不変性:** カメラの位置が変わっても、一貫した理解を維持できます。

投稿者は、この技術がAR/VRなどの分野で、ユーザーが自然言語を使って動的な3Dオブジェクトとインタラクトするのに役立つ可能性があると述べています。ただし、計算コストが高く、リアルタイムアプリケーションには限界があるかもしれないとも指摘しています。

2. **ポストに対する興味深いコメント**

現時点ではコメントは投稿されていません。


---

# [D] Confidence score behavior for object detection models

**Upvotes**: 3



[View on Reddit](https://www.reddit.com/r/MachineLearning/comments/1jc8icd/d_confidence_score_behavior_for_object_detection/)

はい、承知いたしました。以下に、ご質問への回答を記載します。

**1. このポストの内容**

このRedditの投稿は、YOLO（You Only Look Once）という物体検出モデルの出力である「信頼度スコア」の挙動に関する質問です。投稿者は、検出されたオブジェクト（例えば「犬」）に対して、YOLOモデルが出力する他のクラス（例えば「猫」）の信頼度スコアが非常に低い（ほぼ0に近い）ことに疑問を持っています。

具体的には、次のような状況を想定しています。

*   YOLOモデルがある物体を検出する。
*   その物体は「犬」として80%の信頼度で検出される。
*   同じ領域で「猫」である可能性も10%程度あるとモデルが判断した場合、「猫」の信頼度スコアもそれなりに高い値になることを期待する。
*   しかし実際には、「猫」の信頼度スコアは非常に低い値（0.01以下）になってしまう。

投稿者は、YOLOモデルの構造（特に分類ヘッドのシグモイド関数）から考えると、各クラスは独立した二値分類として扱われるはずであり、他のクラスの信頼度スコアが極端に低くなるのは不自然だと考えています。そして、非最大クラスの信頼度を適切に保つために、どのようなテクニックが一般的に用いられているのかを知りたいと考えています。

要するに、投稿者は、物体検出モデルが、最も可能性の高いクラス以外についても、それなりの信頼度スコアを出力するようにしたいと考えており、そのための方法を模索しています。

**2. このポストに対するコメントのうち、特に興味深いもの**

提示されたコメントは1件のみですが、これは非常に興味深い指摘をしています。

このコメントは、投稿者の「モデルが猫を0.1の信頼度で認識しているはずだ」という仮定を疑っています。コメントの要点は以下の通りです。

*   モデルが「猫」の信頼度スコアを0.001と返している場合、それが実際にモデルの自信度である可能性がある。
*   モデルは、他の物体と重なっているような状況で猫を見たことがないかもしれない。
*   このような状況の猫の画像をデータセットに追加し、モデルを訓練して、モデルが正しくオーバーフィットするかどうかを確認するのが良い。

このコメントの興味深い点は、単にモデルの動作がおかしいと考えるのではなく、モデルが学習データに基づいて妥当な判断をしている可能性を指摘している点です。つまり、モデルが低い信頼度スコアを出力するのは、モデルがそのように学習した結果であり、モデルの内部構造の問題ではなく、学習データの問題である可能性があることを示唆しています。

このコメントは、投稿者が問題を解決するための具体的なアプローチ（学習データの拡充と再学習）を提案しており、実践的なアドバイスとして非常に価値があります。


---

# [R] Block Diffusion: A Hybrid Language Model Combining Autoregressive and Diffusion Approaches for Flexible-Length Generation

**Upvotes**: 25



[View on Reddit](https://www.reddit.com/r/MachineLearning/comments/1jbpqsp/r_block_diffusion_a_hybrid_language_model/)

はい、承知いたしました。以下に、ご質問への回答を順を追って詳細に説明します。

**1. ポストの内容の説明**

このRedditのポストは、新しい言語モデル「Block Diffusion」に関するものです。Block Diffusionは、従来の言語モデルの2つの主要なアプローチである「自己回帰モデル (Autoregressive Model)」と「拡散モデル (Diffusion Model)」を組み合わせたハイブリッドモデルです。

*   **背景:** 従来の拡散言語モデルは、性能面で自己回帰モデルに劣り、生成されるテキストの長さが固定されているという課題がありました。

*   **Block Diffusionの仕組み:**

    *   テキストを「ブロック」と呼ばれるチャンクに分割します。
    *   ブロック間の依存関係は自己回帰的に処理します（つまり、前のブロックの内容に基づいて次のブロックを生成します）。
    *   各ブロック内部のテキスト生成には、拡散モデルの手法を用います（並列処理が可能）。
    *   これにより、自己回帰モデルの効率性と拡散モデルの制御性の両方を実現することを目指しています。

*   **主な技術的特徴:**

    *   テキストを柔軟な長さのブロックで処理
    *   KVキャッシュと並列トークンサンプリングによる効率化
    *   データ駆動型のノイズスケジュール（一様なノイズスケジュールではなく、分散最小化に基づく）
    *   C4検証データセットで9.37のperplexityを達成（拡散言語モデルとして最高水準）
    *   任意の長さのテキストを生成可能（従来の拡散言語モデルでは不可能）
    *   自己回帰と拡散のアプローチのバランスを取るための特殊な目的関数を使用

*   **利点:**

    *   自己回帰モデルと拡散モデルの良い点を組み合わせている
    *   効率性と制御性のバランスが取れている
    *   可変長のテキスト生成が可能

*   **投稿者の意見:**

    *   Block Diffusionは、言語モデルのアーキテクチャに関する考え方に大きな影響を与える可能性がある
    *   実用的なアプリケーションにおいて、可変長のテキスト生成と並列処理の両立が特に重要になる可能性がある

*   **まとめ:** Block Diffusionは、テキストをブロック単位で処理することで、自己回帰モデルと拡散モデルを組み合わせた新しい言語モデルであり、性能、効率、柔軟性の向上を実現しています。

**2. ポストに対するコメントのうち、特に興味深いもの**

投稿につけられたコメントは一つのみで、以下のとおりです。
* 3 upvotes: Does anyone has any hot takes on it?

Seems very promising to me to avoid getting stuck after a single bad token precision, and avoid hallucinations too because the models generally try to justify what they wrote and follow the down spiral.

Isn't it the best world of AR and diffusion out together?

このコメントの興味深い点は、Block Diffusionが潜在的に抱える問題を解決しうる点について言及している点です。具体的には、以下の2点です。

*   **「悪いトークン精度の後の行き詰まりを避ける」:** 自己回帰モデルでは、生成の初期段階で不適切なトークン（単語や文字）を選択すると、その後の生成全体に悪影響が及び、期待されるテキストから大きく外れてしまうことがあります。Block Diffusionは、ブロック内での拡散モデルの利用により、この問題が軽減される可能性があります。

*   **「幻覚（ハルシネーション）を避ける」:** 大規模言語モデルは、事実に基づかない情報を生成することがあります（幻覚）。コメント主は、Block Diffusionが生成された内容を正当化しようとする傾向があり、それによって幻覚が抑制されるのではないかと期待しています。

コメント主は、自己回帰モデルと拡散モデルの良い点を組み合わせたBlock Diffusionを評価していることがわかります。


---

# These guys never rest!

**Upvotes**: 297

![Image](https://i.redd.it/4hmgoyhlsyoe1.png)

[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jcbt5l/these_guys_never_rest/)

1.  **ポストの内容の説明:**
    *   タイトルは「These guys never rest!（彼らは決して休まない！）」であり、何らかの活動が非常に活発であることを示唆しています。
    *   画像へのリンク（[https://preview.redd.it/sgdez739tyoe1.png?width=1080&format=png&auto=webp&s=1bc75df09e57c50d4aaf6256780bbebd582982ef](https://preview.redd.it/sgdez739tyoe1.png?width=1080&format=png&auto=webp&s=1bc75df09e57c50d4aaf6256780bbebd582982ef)）が提示されており、この画像が活動の活発さを示す具体的な内容だと考えられます。（ただし、画像自体はテキストからは確認できません。）
    *   ポストは93のupvoteを得ています。

    したがって、このポストは、何らかのグループまたは個人が継続的に活動している様子を賞賛しているか、または皮肉を込めて指摘している可能性があります。画像の内容が分かれば、より正確な意味合いを理解できます。

2.  **特に興味深いコメント:**

    *   **"Why not simply train Qwen4?" (22 upvotes):** このコメントは、ある特定のモデル（Qwen4）のトレーニングに関する提案または疑問を提起しています。Qwenが何らかの機械学習モデル、特に大規模言語モデルであると推測できます。なぜQwen4をトレーニングしないのかという質問は、Qwenに関連する活動や開発に関する議論を促す可能性があります。
    *   **"Waiting for Qwen3" (9 upvotes):**  これはQwen3というモデルのリリースまたは利用可能になることを期待しているコメントです。Qwen4に関する質問があることから、Qwen3も同様の機械学習モデルである可能性が高く、前のバージョンであると考えられます。このコメントは、Qwenモデルの開発ロードマップやリリーススケジュールに関心があることを示しています。

    これらのコメントは、ポストが言及している活動が、Qwenというモデルファミリーの開発に関連している可能性を示唆しています。Qwenモデルの進化やトレーニングに関する議論は、機械学習や自然言語処理に関心のある人々にとって興味深い情報源となるでしょう。


---

# Got new mac studio. What model can I run?

**Upvotes**: 38

![Image](https://i.redd.it/l2st9obzj0pe1.jpeg)

[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jch36h/got_new_mac_studio_what_model_can_i_run/)

1.  **ポストの内容の説明:**

    このRedditのポストは、あるユーザーが新しいMac Studioを購入したことを知らせるもので、そのMac Studioで実行可能な機械学習モデルの種類について質問しています。タイトル「Got new mac studio. What model can I run?」は、直訳すると「新しいMac Studioを手に入れた。どんなモデルを実行できる？」となり、ユーザーがMac Studioの性能を最大限に活かせるモデルを知りたいと考えていることがわかります。つまり、Mac Studioのスペックを考慮して、どの程度の規模の機械学習モデルが快適に動作するか、あるいは特定のモデルが推奨されるか、といった情報を求めていると考えられます。

2.  **特に興味深いコメント:**

    *   **「Reflection 70B」（41 upvotes）:** このコメントは、具体的なモデル名を提示している点が非常に興味深いです。「70B」はおそらく700億パラメータを持つモデルであることを示唆しており、大規模言語モデルの一種である可能性が高いです。このコメントが高評価を得ていることから、Mac Studioでもある程度の規模の言語モデルが実行可能であること、そしてその中でも「Reflection 70B」が特に適している可能性があることを示唆しています。具体的なモデル名が提示されているため、質問者はこのモデルを調べて、自分の目的に合うかどうかを判断する出発点にすることができます。

    *   **「Foundation models probably」（23 upvotes）:** このコメントは、具体的なモデル名ではないものの、「Foundation models（基盤モデル）」というカテゴリを提案している点が興味深いです。基盤モデルは、大量のデータで事前学習された汎用的なモデルであり、様々なタスクに適用できるため、Mac Studioの汎用性を活かせる可能性を示唆しています。このコメントも、ある程度の規模のモデルが動作することを暗に示唆しており、質問者は「Foundation models」というキーワードで検索し、Mac Studioで利用可能なモデルを探すことができます。

    *   **「Americas' next top model」（9 upvotes）:** このコメントは、質問とは直接関係のない、単なるジョークです。 upvoteの数が他のコメントに比べて少ないため、質問者にとって役立つ可能性は低いと考えられます。

---

# Baidu releases X1, a (closed?) model that matches R1 and ERNIE 4.5, that matches GPT 4.5

**Upvotes**: 67



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jcchtq/baidu_releases_x1_a_closed_model_that_matches_r1/)

1.  **ポストの内容の説明:**

このRedditのポストは、中国の検索エンジン大手Baidu（バイドゥ）が発表した新しいAIモデル「X1」に関するものです。投稿者は、BaiduがX1を、自社の既存モデルであるERNIE 4.5やDeepseek R1と同等の性能を持ち、OpenAIのGPT-4.5に匹敵すると主張していることを伝えています。ただし、X1がクローズドなモデルであるかどうか（ソースコードやモデルへのアクセスが制限されているかどうか）は不明とされています。投稿文には、Baiduの公式X（旧Twitter）アカウントへのリンクが添付されています。

2.  **特に興味深いコメント:**

*   **Deepseek R1との比較:** 「The performance seems worser than Deepseek R1」というコメントは、X1の性能がDeepseek R1よりも低い可能性があることを指摘しており、注目に値します。特に、AIモデルの性能比較は主観的になりやすく、具体的なベンチマークやタスクによって評価が異なるため、ユーザーの個人的な評価が示されているのは興味深いです。
*   **ベンチマークの比較対象に関する指摘:** 「In the benchmark graphs, Baidu is comparing X1 to Deepseek-V3, the non-reasoning instruction tuned model, not Deepseek-R1.」というコメントは、Baiduが公開しているベンチマークグラフにおいて、X1の比較対象がDeepseekの最新モデルR1ではなく、Deepseek-V3という推論能力が低いモデルである点を指摘しています。これは、Baiduが意図的にX1の性能を良く見せようとしている可能性を示唆しており、批判的な視点として重要です。添付された画像も、このコメントを裏付ける資料となっている可能性があります。


---

# Who's still running ancient models?

**Upvotes**: 99



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jc9meu/whos_still_running_ancient_models/)

はい、承知いたしました。以下に詳細な回答を記述します。

1.  **このポストの内容の説明**

このRedditの投稿は、AIモデルの急速な進化に対する驚きと感慨を表明しています。投稿者は、わずか1年前には70B（700億パラメータ）規模のモデルが必要だと考えられていたタスクが、現在では14-32B程度のモデルで十分にこなせるようになったことに感銘を受けています。

具体的には、`gemma3`, `mistralsmall`, `phi4`, `qwq`, `qwen`といった比較的小規模なモデルの性能向上に注目し、過去に利用していた大規模なモデル（`llama405B`, `deepseek dyanmic quants`）を削除する決断をしています。

その上で、過去のモデル（`guanaco`, `dolphin-llama2`, `vicuna`, `wizardLM`, `nous-hermes-llama2`など）を再ダウンロードし、初期のAIモデルを懐かしむとともに、その進歩を改めて認識しようとしています。

投稿者は、過去のモデルを動かすことで、現在の高性能なモデルに対する感謝の念を深め、技術の進歩の速さを忘れないようにしたいと考えています。

2.  **このポストに対するコメントのうち、特に興味深いもの**

*   **1つ目のコメント（58 upvotes）**

    「大規模な企業では、10年前あるいはそれ以前からAIを利用している企業は、アーキテクチャの面で少なくとも3年以上前の古いモデルをまだ本番環境で運用していることは間違いないでしょう」というコメントは、AI技術の最先端と実際のビジネス現場とのギャップを示唆しており、興味深いです。 研究開発段階では常に最新のモデルが注目されますが、大規模な企業では既存のインフラやシステムとの互換性、コスト、信頼性などの理由から、古いモデルを使い続けることが多いという現実を反映しています。理想的には、古いモデルを再トレーニングしていることが望ましいと付け加えています。
*   **2つ目のコメント（37 upvotes）**

    `NousResearch/Nous-Capybara-34B`というモデルを挙げ、「時代を先取りしていた」と評価しているコメントも興味深いです。 具体的にどのような点が優れていたのかは不明ですが、過去のモデルの中にも、現在の視点から見ても優れた特徴を持っていたものが存在することを示唆しています。
*   **3つ目のコメント（21 upvotes）**

    `Guanaco 65b ggml`をGGUF形式に変換して再利用しようとした経験談は、ノスタルジーだけでなく、過去のモデルの可能性を再評価しようとする試みとして共感を呼びます。 特に、「より人間らしい応答/文章を得るため」という目的が興味深いです。しかし、2048コンテキストという制限が課題になったようです。


---

# Qwen2 72b VL is actually really impressive. It's not perfect, but for a local model I'm certainly impressed (more info in comments)

**Upvotes**: 20

![Image](https://i.redd.it/1t90zqok80pe1.png)

[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jcggwb/qwen2_72b_vl_is_actually_really_impressive_its/)

1. **ポストの内容の説明:**

このRedditのポストは、Qwen2 72b VLというローカルモデル（おそらく大規模言語モデル）が非常に印象的であるという意見を述べています。完璧ではないものの、ローカル環境で動作するモデルとしては十分に優れていると評価しています。詳細はコメント欄に記載されているようです。

2. **特に興味深いコメント:**

*   **「If this is Qwen 2, maybe you'd be interested to learn Qwen 2.5 72B VL is also now available.」** (3 upvotes):

    このコメントは、投稿者がQwen2 72b VLに感銘を受けていることを踏まえ、さらに新しいバージョンであるQwen 2.5 72B VLも利用可能であることを知らせています。モデルの進化が速いことを示唆しており、投稿者の関心を引く可能性が高い情報です。より優れたモデルが存在するかもしれない、という事実は非常に興味深いです。

---

# Made a ManusAI alternative that run locally

**Upvotes**: 302



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jbwk65/made_a_manusai_alternative_that_run_locally/)

はい、承知いたしました。以下に質問の回答を記載します。

1.  **このポストの内容の説明:**

このRedditポストは、投稿者（Fosowl）とその友人が開発した、ManusAIの代替となるローカルで実行可能なAIエージェントシステム「agenticSeek」について紹介しています。

**主なポイント:**

*   **ローカル実行:** すべての処理がユーザーのコンピュータ上で実行されるため、データプライバシーとセキュリティが向上します。
*   **機能:**
    *   **Webエージェント:** 自動的なウェブ検索とブラウジング。
    *   **コードエージェント:** 半自律的なコーディング能力（試行と再試行を含む）。
    *   **ファイルエージェント:** Bashコマンド実行とファイルシステム操作。
    *   **ルーティングシステム:** ユーザーの指示に基づいて最適なエージェントを選択。
    *   **セッション管理:** 会話の保存と読み込み。
    *   **APIツール:** Webiやフライト検索など、様々なAPIとの連携。
    *   **メモリシステム:** 各エージェントが個別の記憶を持ち、要約モデルを使用して長期的な記憶を圧縮（実験段階でデフォルトでは無効）。
    *   **テキスト読み上げ & 音声テキスト変換**
*   **今後の機能:**
    *   **タスクプランニング:** タスクを分解し、適切なエージェントを起動。
    *   **ユーザー設定の記憶:** ユーザーの好みを記憶。
    *   **OCRシステム:** エージェントがユーザーの画面を認識。
    *   **RAGエージェント:** 個人的なドキュメントとのチャット。
*   **openManusとの違い:** ローカル実行に重点を置き、既存のフレームワークに頼らずにできる限り独自に構築。
*   **開発チーム:** フランスと台湾に拠点を置く2人の開発者。
*   **GitHubリポジトリ:** [https://github.com/Fosowl/agenticSeek](https://github.com/Fosowl/agenticSeek)でソースコードが公開されています。
*   **目的:** フィードバック、支援、貢献者の募集。

2.  **特に興味深いコメント:**

以下に、このポストに対するコメントのうち、特に興味深いものをいくつか挙げます。

*   **「Finally. Something that is readable and not in Chinese. Not hating, I’m unable to comprehend anything from those tutorials. I am going to try this in one hour.」 (54 upvotes)**
    *   **なぜ興味深いか:** このコメントは、ManusAI関連の他のプロジェクト（特に中国語のドキュメントが多いもの）に対する不満を表明しており、英語で理解しやすいドキュメントが提供されていることへの感謝を示しています。また、ローカル実行可能なAIへの関心の高さを表しています。
*   **「Keep going guys, the world need more this!」 (4 upvotes)**
    *   **なぜ興味深いか:** このコメントは、ローカルで実行可能なAIエージェントの開発に対する潜在的な需要と、このプロジェクトへの期待を示しています。
*   **「Just update the Readme creepy image. It's scarying me out!」**
    *   **なぜ興味深いか:**　技術的な内容以外にも、ユーザーエクスペリエンスに関する率直な意見が述べられています。　Readmeに掲載されている画像が怖く感じられるというフィードバックは、開発チームが改善する上で参考になります。

これらのコメントは、このプロジェクトが持つ可能性と、開発チームが取り組むべき課題を示唆しています。


---

# A tip to make QwQ less verbose

**Upvotes**: 23



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jcdsat/a_tip_to_make_qwq_less_verbose/)

1.  **ポストの内容の説明:**

このRedditのポストは、大規模言語モデルのQwQ（具体的なモデル名は不明）を使用する際のヒントを提供しています。投稿者は、QwQがユーザーの意図を過剰に解釈する傾向があると感じており、それを軽減するために「few-shot learning」のアプローチ、つまり、モデルに具体的な例をいくつか与えることが有効だと述べています。

具体的には、以下の点が強調されています。

*   **例の重要性:** QwQは優れたfew-shot学習者であり、単に例をコピーするのではなく、その背後にある「より大きな全体像」を理解しようとする。
*   **プロンプトの改善:** 良質な例を与えることで、モデルはユーザーが最初に書いたプロンプトよりも優れたプロンプトを生成できる。
*   **専門用語への固執の少なさ:** 他のローカルモデルとは異なり、QwQは単語遣いやスタイルに固執せず、例を通して意図を理解しようとする。
*   **具体的な例:** 投稿者は、研究論文を会話形式に変換する際に、QwQに例を与えることで、論文の要約と、読者を引き込むための構成（フック、問題、メカニズム、結果、重要性）をモデルが自力で作成できた例を示しています。
*   **限界:** 完璧ではないものの、例を与えることで出力が大幅に改善される。
*   **使用環境:** ExLlamaエンジンを使用し、推奨設定に従っている。

要するに、投稿者はQwQのプロンプトを作成する際に、具体的な例を与えることで、モデルの意図理解を助け、より洗練された出力を得られると主張しています。

2.  **特に興味深いコメント:**

唯一のコメントが特に興味深い理由は、以下の点が挙げられます。

*   **ユーザー参加の重要性:** 新しいAIモデルのリリースは新しいフロンティアであり、GPUリッチな人々が初期段階の研究を行う一方で、ユーザーが実際にモデルを使用し、その能力を引き出すことで、研究を完成させるという考えを示唆している。
*   **モデルとの相互作用の進化:** ユーザーとモデルの相互作用は、単なるツールの使用ではなく、文化的な交流や共進化の様相を呈しているという、より深い考察が述べられている。
*   **人間の専門性の持続性:** 一般的な知能を持つAIが登場しても、人間は特定の分野に特化する必要があるだろうという予測は、AIの進化における人間の役割を再考させる。
*   **機械学習の発見者:** 機械学習が人間によって発見されたのか、それとも機械学習が人間を発見したのかという問いは、技術の進歩と人間の理解の複雑な関係を示唆している。
*   **高度な比喩表現:** ドクター・マイケル・レビンの言及や、「ever present pool of intelligence」という表現は、AIの可能性をより詩的かつ哲学的に捉えている。

このコメントは、単にプロンプトエンジニアリングのヒントに感謝するだけでなく、AI技術の進化、人間との関わり方、そして知能の本質について深く考察しており、非常に興味深いと言えます。


---

# I hope uncensored gemma3b come soon enough... the model is unbearable boring as it is know.

**Upvotes**: 89



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jc3fkd/i_hope_uncensored_gemma3b_come_soon_enough_the/)

はい、承知いたしました。以下に、ご質問に対する回答を記載します。

1.  **このポストの内容の説明**

このRedditポストは、GoogleのGemma 3BというAIモデルに対する不満を表明しています。投稿者は、Gemma 3Bが非常に退屈で、個性がなく、企業の広報文のような無難な回答ばかりで、楽しくないと述べています。以前に楽しめたDarkest MuseやGemma 2 9B simpoバージョンの方が良かったと述べています。NSFW（Not Safe For Work：職場での閲覧に不適切なコンテンツ）な内容を求めているわけではなく、単に会話をする上でAIの反応が面白くないことを問題視しています。全体的に、Gemma 3Bがつまらなく、創造性や個性に欠けていると感じているようです。

2.  **このポストに対するコメントのうち、特に興味深いもの**

このポストに対するコメントで特に興味深いのは、以下の2点です。

*   **87 upvotesのコメント:** このコメントは、Gemmaモデルの過剰な検閲と、その結果としての不自然な反応を具体的に示しています。AIが画像の内容を適切に分析できず、代わりに女性の扱いに関する倫理的な話題に逸れてしまう事例は、Gemmaモデルが本来のタスクを遂行する能力を著しく損なっていることを示唆しています。これは、AIモデルの意図的な「脳の一部切除」によって、性能が低下しているという投稿者の意見を裏付けています。
*   **13 upvotesのコメント:** このコメントは、Gemmaモデルの潜在能力について異なる視点を提供しています。特定の条件下（例えば、具体的なキャラクターになりきらせる）では、Gemma 27Bモデルが検閲を回避し、優れたロールプレイング能力を発揮できると述べています。このコメントは、Gemmaモデルの性能が、設定や使用方法によって大きく左右される可能性を示唆しており、モデル自体に問題があるのではなく、ユーザー側の設定や技術的な問題が原因である可能性も示唆しています。また、Gemmaモデルの自然な応答を評価しており、他のモデルと比較して優れている点を強調しています。


---

# How I used entropy and varentropy to detect and remediate hallucinations in LLMs

**Upvotes**: 13



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jcef1d/how_i_used_entropy_and_varentropy_to_detect_and/)

1.  **ポストの内容の説明:**

このRedditのポストは、投稿者がLLM（大規模言語モデル）におけるハルシネーション（もっともらしい嘘や誤った情報の生成）を検出し、修正するためにエントロピーとバリエントロピーという概念を用いた研究を紹介するブログ記事へのリンクを共有しています。

*   **概要:** 投稿者は、このブログ記事がLLM、特にルーティングや関数呼び出しシナリオで使用される高速で効率的な言語モデルに関する一連の研究を紹介する入門的な内容であることを説明しています。
*   **対象読者:** LLMのエキスパートには内容が浅すぎる可能性がある一方で、LLMについて学び始めたばかりの人にとっては、いくつかの機械学習の概念を理解するための適切な導入となる可能性があると述べています。
*   **ブログ記事へのリンク:** 記事へのリンク ([https://www.archgw.com/blogs/detecting-hallucinations-in-llm-function-calling-with-entropy-and-varentropy](https://www.archgw.com/blogs/detecting-hallucinations-in-llm-function-calling-with-entropy-and-varentropy)) が提供されており、ブログ記事のタイトルから、エントロピーとバリエントロピーを用いてLLMの関数呼び出しにおけるハルシネーションを検出する方法について解説していることがわかります。
*   **研究の意図:** LLMのハルシネーションを抑制するための研究の一部であることがわかります。

2.  **特に興味深いコメント:**

*   **"one of not many cases where semantic entropy = naive entropy." (セマンティックエントロピー=ナイーブエントロピーとなる数少ないケースの一つ)**

    このコメントは、投稿された記事の内容に対して技術的な洞察を提供しています。通常、エントロピーは、単純な統計的指標として計算される「ナイーブエントロピー」と、意味的な情報を考慮した「セマンティックエントロピー」に区別できます。このコメントは、記事で扱われている特定の状況下では、これらの2つのエントロピーがほぼ同等になるという点を指摘しています。これは、LLMにおけるハルシネーションの検出において、より単純なエントロピー計算でも有効な場合があることを示唆しており、興味深いです。なぜなら、セマンティックエントロピーの計算はより複雑で計算コストが高くなる可能性があるからです。

*   **"Ugh, I'm still waiting for logprobs in Ollama to do similar things and steer the model on the fly." (ああ、Ollamaでlogprobsを使って同じようなことができて、モデルをその場で制御できるようになるのをまだ待っているんだ。)**

このコメントは、LLMの実用的な応用に関するユーザーの関心を反映しています。Ollamaは、ローカルでLLMを実行するためのツールです。このコメントのユーザーは、Ollamaがトークンの確率（logprobs）を利用して、モデルの挙動をリアルタイムで調整できるようになることを望んでいます。これは、ハルシネーションの抑制や、モデルの出力を特定の方向に誘導するために非常に有用な機能です。ユーザーがこのような機能を待ち望んでいることは、LLMの制御可能性と信頼性に対するニーズが高いことを示しています。


---

# GPT-Sovits V3 TTS (407M) Release - 0-Shot Voice Cloning , Multi Language

**Upvotes**: 154



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jbyg29/gptsovits_v3_tts_407m_release_0shot_voice_cloning/)

1.  **ポストの内容の説明**

このRedditのポストは、GPT-SoVITS V3という新しいテキスト読み上げ (TTS) モデルのリリースについて紹介しています。以下に主なポイントをまとめます。

*   **GPT-SoVITS V3の紹介:** GPT-SoVITSの最新バージョン（V3）がリリースされたことを告知しています。以前のバージョンと比較して、パラメータ数が増加（1億6700万から4億700万へ）し、音声クローニングの性能が大幅に向上したと述べています。
*   **0-Shot音声クローニング:** 特に、短い音声サンプル（10秒以下）から音声クローンを作成する0-Shot音声クローニング機能が改善され、オリジナルの声にさらに近いクローンを作成でき、感情の維持もより安定していると説明しています。
*   **多言語対応:** 英語、中国語、日本語、韓国語、広東語に対応していると述べています。特に日本語の0-Shot音声クローニングにおいて、現時点で最高の選択肢であると評価しています。
*   **リリースページと変更履歴:** GitHubのリリースページと、機械翻訳された変更履歴へのリンクを提供しています。
*   **注意点:** GitHubページの音声サンプルはまだV2のものであること、Gradioインターフェースを起動した際にデフォルトでV2が選択されているため、V3に切り替える必要があることを注意喚起しています。
2.  **特に興味深いコメント**

*   **GPT-Sovitsの過去の評価とアップデートへの期待:** 初めのコメントは、投稿者に感謝の意を述べつつ、以前のGPT-Sovitsの印象について言及しています。特に日本語の音声クローニング機能に感銘を受けていたようです。ドキュメントが主に中国語で書かれていたために過小評価されていた可能性があるという指摘は、興味深い点です。また、今回のアップデートを知らなかったため、改めて試してみるという意欲を示しています。
*   **llasa-8bとの比較:** 次のコメントは、llasa-8bという別のモデルとの比較を尋ねています。これは、GPT-SoVITS V3の性能を他の同様の技術と比較したいというニーズを示唆しており、技術的な関心の高さが伺えます。

これらのコメントから、GPT-SoVITSに対する期待と関心、そして技術的な比較へのニーズが存在することがわかります。

