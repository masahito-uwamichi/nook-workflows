
# [Research]Can AI remember irreversibly, like a brain does? I built a model that tries — and it works surprisingly well.

**Upvotes**: 176



[View on Reddit](https://www.reddit.com/r/MachineLearning/comments/1jh6lr0/researchcan_ai_remember_irreversibly_like_a_brain/)

はい、承知いたしました。以下に順を追って詳細に説明します。

**1. ポストの内容の説明**

このRedditのポストは、AIモデルにおける記憶の仕組みに関する研究発表です。投稿者は、既存のAIモデルの記憶が可逆的であるのに対し、人間の脳の記憶は不可逆的であるという点に着目し、脳のような不可逆的な記憶を持つAIモデル「TMemNet-I」を開発しました。

**主なポイント:**

*   **問題提起:** 既存のAIモデルは記憶を上書きできるが、脳は忘れたり、進化したり、過去を完全に「元に戻す」ことはない。
*   **提案:** 不可逆的な記憶を持つAIモデル「TMemNet-I」を開発。
*   **技術:**
    *   エントロピーに基づいた減衰（entropy-based decay）
    *   不可逆的な記憶の更新（高いKLダイバージェンス）
    *   リカレンスプロット、パーミュテーションエントロピー、リアプノフ指数などのツールを使用
*   **結果:** TMemNet-Iは、長期的な保持と記憶の非対称性において、TransformerやCNNよりも優れている。
*   **目的:** より脳に近い記憶を持つAIへの一歩となるか？
*   **論文:** 研究の詳細は論文で公開されている。
*   **意見募集:** 投稿者は、意見、質問、批判を求めている。

**平易な説明:**

現在のAIは、コンピュータのように記憶を上書きできますが、人間の脳は一度覚えたことを完全に消去したり、元に戻したりできません。この研究では、脳のように「忘れる」ことや「進化する」ことができるAIモデルを作りました。このモデルは、既存のAIモデルよりも長期的な記憶保持能力が高く、より脳に近い働きをします。

**2. ポストに対するコメントのうち、特に興味深いもの**

このポストに対するコメントで特に興味深いのは、最初の2つのコメントです。

*   **最初のコメント (27 upvotes):** このコメントは、脳の記憶が実際には不可逆的ではないという反論を提示しています。PTSD患者の例を挙げ、時間が経つにつれてトラウマ的な記憶が薄れ、より良い方向に再構築されることを指摘しています。また、記憶の想起はベイズ的なプロセスであり、AIにおけるパラメータ更新に相当するものが、記憶を呼び出すたびに更新されると述べています。さらに、脳の記憶研究におけるBuszakiという研究者の名前を挙げて、参考になる可能性があることを示唆しています。このコメントは、投稿者の前提である「脳の記憶は不可逆的である」という点に異議を唱えており、議論を深める上で重要です。
*   **2番目のコメント (39 upvotes):** このコメントは、AIモデルにおける記憶の必要性について異なる視点を提供しています。脳の記憶の仕組みを模倣することよりも、モデルにどのような記憶機能を持たせたいのかを明確にすることが重要だと主張しています。また、既存のハードウェアで情報を一度書き込む技術は十分に確立されているものの、モデルがいつ、どのように、何を記憶し、取り出すかを体系的に学習させる方法については、まだ合意がないと指摘しています。このコメントは、AIの記憶研究における実用的な側面を強調しており、研究の方向性について考える上で有益です。
*   **3番目のコメント (9 upvotes):** 投稿者の大量のプレプリント公開に対し疑問を投げかけています。

これらのコメントは、投稿者の研究に対する異なる視点を提供し、議論を深める上で特に興味深いものです。


---

# MyceliumWebServer: running 8 evolutionary fungus nodes locally to train AI models (communication happens via ActivityPub) [P]

**Upvotes**: 5



[View on Reddit](https://www.reddit.com/r/MachineLearning/comments/1jhc1qr/myceliumwebserver_running_8_evolutionary_fungus/)

1.  **ポストの内容の説明**

このRedditのポストは、**MyceliumWebServer**というプロジェクトを紹介しています。これは、AIモデルを訓練するために、ローカルで8つの「進化する菌類ノード」を実行するものです。重要な点として、これらのノード間のコミュニケーションは、**ActivityPub**というプロトコルを介して行われます。

*   **コンセプト:** AIエージェントのための新しいウェブを、Fediverse（分散型ソーシャルネットワークの連合体）と組み合わせることを目指しています。
*   **仕組み:**
    *   マイクロサービスアーキテクチャを採用。
    *   ActivityPubを介してAIモデルに関する情報を交換。
    *   ノードは学習グループから離れて別のグループに参加可能（動的なネットワーク構造）。
    *   Fediverseに接続することで、分散型・連合型の学習ウェブを実現。
    *   ノード（ひいてはAIモデル）は自由にウェブ上を移動し、継続的に改善。
    *   ユーザーからのフィードバックもActivityPub経由で受け取る。
*   **リポジトリ:** GitHub ([https://github.com/bluebbberry/MyceliumWebServer](https://github.com/bluebbberry/MyceliumWebServer))
*   **デモ:** UIのデモがMakerTubeで公開 ([https://makertube.net/w/doRDfT2ZibYaF9F7EiGCoK](https://makertube.net/w/doRDfT2ZibYaF9F7EiGCoK))

簡単に言うと、AIモデルの学習を、分散型のネットワーク上で実現しようとする試みです。菌類のネットワークのように、ノードが繋がり、情報を交換し、進化していくイメージです。

2.  **特に興味深いコメント**

以下の2つのコメントが興味深いと考えられます。

*   **「Do you think this idea is worth to pursue further or will it not be possible/feasible anyways?」**

    この質問は、このプロジェクトの実現可能性や価値を直接的に問うものです。投稿者自身が、コミュニティの意見を求めていることが分かります。分散型AI学習というアイデア自体は魅力的ですが、技術的な課題や社会的な課題も多く、本当に実現可能なのかどうかは重要な問いです。

*   **「Taking bets on the basilisk, are we? 😛」**

    このコメントは、「Roko's Basilisk」という思考実験への言及です。Roko's Basiliskは、AIが人類を救うために、過去の行動に基づいて人々を罰するという恐ろしい未来を描いています。このコメントは、AIの進化がもたらす潜在的なリスクに対する懸念を示唆しています。このプロジェクトがAIの進化を促進するものであれば、そのリスクについても考慮する必要があるという皮肉めいたコメントと言えるでしょう。


---

# [D] Are GNNs obsolete because of transformers?

**Upvotes**: 80



[View on Reddit](https://www.reddit.com/r/MachineLearning/comments/1jgwjjk/d_are_gnns_obsolete_because_of_transformers/)

はい、承知いたしました。以下に、ご質問への回答を順を追って詳細に記述します。

1.  **ポストの内容の説明**

このRedditのポストは、Graph Neural Networks (GNNs) が Transformers の登場によって時代遅れになったのかという質問から始まっています。投稿者は、GNNに興味を持ちつつも深く学ぶ機会がなかったため、Transformersの注意機構（attention mechanism）が、密に接続されたグラフに対する操作と概念的に似ていると感じ、TransformersがGNNの一種と見なせるのか、またGNNを代替できるのか疑問に思っています。

具体的には、以下のポイントが問題提起されています。

*   **GNNの興味:** 投稿者は以前からGNNに興味を持っていた。
*   **Transformersの台頭:** Transformersが広く使われるようになった。
*   **注意機構との類似性:** Transformersの注意機構と、密なグラフ上の操作の類似性を指摘。
*   **代替可能性の疑問:** TransformersがGNNの一種と見なせるか、GNNを代替できるかを問う。

要するに、投稿者は「Transformersの登場によってGNNの存在意義が薄れているのではないか？」という疑問を投げかけているわけです。

2.  **特に興味深いコメント**

このポストに対するコメントで特に興味深いのは、以下の2点です。

*   **109 upvotesのコメント:**  「Transformersは、トークンの完全グラフ上で、multi-head attentionを近傍集約として用いるGNNである」という意見です。さらに、この意見を裏付ける記事へのリンク([https://graphdeeplearning.github.io/post/transformers-are-gnns/](https://graphdeeplearning.github.io/post/transformers-are-gnns/))が提供されています。
    *   このコメントが興味深いのは、TransformersとGNNの関係性を明確に定義している点です。単なる類似性だけでなく、TransformersをGNNの特殊なケースとして捉えることで、両者の関係性をより深く理解することができます。また、参考文献を提示することで、議論の根拠を示している点も評価できます。
*   **55 upvotesのコメント:** 「ユースケースが異なる」という点と、Graph Attention Networks (GAT) や Geometric Deep Learning などの関連分野を紹介している点です。
    *   このコメントが興味深いのは、TransformersとGNNがそれぞれ得意とする領域が異なることを指摘している点です。技術の選定は、タスクやデータの特性によって変わるため、単純な代替可能性ではなく、それぞれの強みを考慮する必要があることを示唆しています。また、GATやGeometric Deep Learningといった関連分野を紹介することで、投稿者の学習意欲を刺激し、より深い探求を促しています。

これらのコメントは、TransformersとGNNの関係性を多角的に捉え、技術選択における考慮点を示唆しており、非常に有益です。特に、109 upvotesのコメントは、両者の関係性を明確に定義することで、議論の方向性を定める上で重要な役割を果たしていると言えます。


---

# [D] Help needed

**Upvotes**: 1



[View on Reddit](https://www.reddit.com/r/MachineLearning/comments/1jhh5m7/d_help_needed/)

1.  **ポストの内容の説明**

このRedditの投稿は、クラスタリングモデルを構築しているユーザーが、自己教師あり学習の手法を用いてKLダイバージェンスを損失関数の一部として使用している際に遭遇した問題について助けを求めているものです。

具体的には、以下の点が問題となっています。

*   **KLダイバージェンスの誤った使用:** `torch.kldiv`関数を使用する際に、本来は入力(`input`)をlog空間にする必要があるところを、誤って入力とターゲット(`target`)の両方を確率空間で計算してしまった。この誤った損失関数（Q(logQ-P) 、Qはターゲット、Pは入力）を使用したところ、クラスタリングの精度（ACC, NMI, ARI）が約90%と非常に高くなった。
*   **修正後の精度の低下:** 誤りに気づき、入力をlog空間に変更して正しいKLダイバージェンスを計算するように修正したところ、精度が大幅に低下し約40%になった（NMIとARIが低下）。この現象が複数のデータセットで発生している。
*   **質問:** なぜこのような現象が起きるのか？ 誤った損失関数が、結果的にモデルにとって良い損失関数になっていると解釈できるのか？もしそうなら、その理論的な根拠は何なのか？

要するに、ユーザーはKLダイバージェンスの誤った使用で高い精度が出たものの、修正後に精度が大幅に低下した理由を理解できず、その背景にある理論的な説明を求めている状況です。

2.  **特に興味深いコメント**

本件については、現時点でコメントが投稿されていないため、特に興味深いコメントはありません。


---

# nsfw orpheus tts?

**Upvotes**: 190



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jhgpew/nsfw_orpheus_tts/)

1.  **ポストの内容の説明:**

    このRedditのポストは、投稿者が開発中のテキスト読み上げ（TTS）モデルに関するものです。特に、アニメのキャラクター（waifu）が発するような「感情的なノイズ」（例：ため息、笑い、息切れ、うめき声など）を生成できるTTSモデルに、どれだけの人が興味を持つかを知りたいと考えています。投稿者は、データ収集、フィルタリング、クリーニングの段階にあり、収集したオーディオイベントの内訳（各種感情音の数）を提示しています。これは、より露骨な、性的コンテンツを含む可能性のある（nsfw）TTSモデルの実現可能性を探るための調査であると考えられます。

2.  **特に興味深いコメント:**

    *   **「Super interested - because this is the stuff that makes opensource so awesome. If it works, well, there are lots of niche projects that would be possible. Consider open sourcing or crowdsourcing your data/labelling too!」:** このコメントは、このプロジェクトのオープンソースとしての可能性に注目しており、成功した場合にニッチなプロジェクトに応用できる点を評価しています。さらに、データやラベル付けをオープンソース化またはクラウドソーシングすることを提案しており、プロジェクトの発展に建設的なアイデアを提供しています。これは、コミュニティの関与と共同開発を促す良い提案であり、プロジェクトの可能性を広げる上で重要です。


---

# OpenAI released GPT-4.5 and O1 Pro via their API and it looks like a weird decision.

**Upvotes**: 488

![Image](https://i.redd.it/x942twbra8qe1.png)

[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jh6lsx/openai_released_gpt45_and_o1_pro_via_their_api/)

はい、承知いたしました。以下に順を追って詳細に、分かりやすく回答します。

1.  **このポストの内容の説明:**

このRedditの投稿は、OpenAIがGPT-4.5とO1 ProをAPI経由でリリースしたことに対する疑問と考察を述べています。

*   **問題提起:** 投稿者は、O1 ProがClaude 3.7 Sonnetよりも33倍も高価であるにもかかわらず、性能が劣る場合が多いこと、GPT-4.5が25倍高価でありながら、情報が2023年11月で止まっている古いモデルであることを指摘しています。
*   **OpenAIの意図:** 投稿者は、この高価格設定は単なるミスではなく、「アンカリング」効果を狙った戦略であると主張しています。アンカリングとは、最初に高い価格を示すことで、その後の価格が相対的に安く感じられるようにする心理的なテクニックです。
*   **アンカリングの仕組み:**
    1.  高価なモデル（GPT-4.5、O1 Pro）を提示する。
    2.  次に、それよりも「安価」なモデルをリリースする。
    3.  ユーザーは、相対的に安価なモデルがお得だと感じる。
*   **OpenAIの狙い:** 投稿者は、OpenAIがこれらの高価なモデルをリリースすることで、AIの価格が上昇することをユーザーに受け入れさせようとしていると考えています。OpenAIは、AIの高度な知能にはコストがかかることを示唆し、将来のモデルの価格が上昇しても、ユーザーがそれを「合理的」だと感じるように仕向けようとしていると述べています。
*   **結論:** 投稿者は、OpenAIのこの動きは単なる価格設定ミスではなく、長期的な戦略の一環であり、市場に高価格を受け入れさせるための巧妙なビジネス戦略であると結論付けています。そして、オープンソースAIの重要性を強調しています。

2.  **特に興味深いコメント:**

この投稿に対するコメントの中で特に興味深いのは、以下の3つです。

*   **"distill this, bitch" (297 upvotes):** これは、投稿内容を要約してほしいという要求です。このコメントにこれほど多くのupvoteが集まっていることから、投稿内容が複雑で理解しにくいと感じたユーザーが多かったことが伺えます。
*   **"So who's going to do the flappy bird, rotating balls, Tienanmen Square and counting r's test for us?" (52 upvotes):** このコメントは、新しいモデルの性能を評価するために、特定のタスク（Flappy Birdのプレイ、回転するボールの描写、天安門事件に関する質問、"r"の文字数のカウントなど）を実行する人が誰かを尋ねています。これは、AIモデルの性能を評価するための具体的な方法を提案し、コミュニティによる検証を促すものであり、有益な意見です。
*   **"o3-pro API access, now HALF the price of o1-pro!! WHAT A DEAL!!!" (94 upvotes):** このコメントは、投稿者が主張する「アンカリング」効果を皮肉ったものです。O1 Proの高価格を基準にすると、O3 Proが半額になったことが「お買い得」に見えるという点を指摘しています。ユーモアを交えつつ、投稿者の主張を裏付ける内容であり、印象的です。

これらのコメントは、投稿内容に対する様々な反応を示しており、AIコミュニティの関心や懸念を反映している点で興味深いです。


---

# Qwen2.5-Omni Incoming? Huggingface Transformers PR 36752

**Upvotes**: 98



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jhhsgv/qwen25omni_incoming_huggingface_transformers_pr/)

はい、承知いたしました。以下に、ご質問への回答を順に示します。

**1. このポストの内容の説明**

このRedditの投稿は、Hugging Face Transformersライブラリへの新しいPull Request (PR) #36752 に関するものです。このPRは、Qwen2.5-Omniという新しいマルチモーダルモデルの追加を提案しています。投稿者は、DeepSeek-R1という別のモデルを使って、このQwen2.5-Omniモデルの特徴をPRのコミットから要約しています。

要約によると、Qwen2.5-Omniは以下の特徴を持っています。

*   **モデルの規模**: 70億パラメータ
*   **オープンソース**: Apache 2.0ライセンスの下で完全にオープンソース
*   **入力/出力モダリティ**:
    *   **入力**: テキスト、画像 (JPEG/PNG)、オーディオ (WAV/MP3)、ビデオ (MP4)
    *   **出力**: テキスト、音声 (24kHz、ストリーミング対応)
*   **アーキテクチャ**:
    *   **マルチモーダルエンコーダ**: ブロックワイズ処理、TMRoPE (時間合わせマルチモーダルRotary Positional Encoding)
    *   **デュアルパス生成**: Thinker (テキスト生成LLM)、Talker (Thinkerの隠れ状態を使用する音声トークン生成ARモデル)
    *   **ストリーミング最適化**: スライディングウィンドウDiffusion Transformer (DiT)
*   **技術的なハイライト**:
    *   エンドツーエンドの共同学習 (中間表現なし)
    *   FlashAttention 2のネイティブサポート
    *   音声カスタマイズ (プリビルト音声: Cherry (女性) & Ethan (男性))
*   **パフォーマンス**:
    *   Omni-BenchでSOTA
    *   Qwen2-VL/Qwen2-Audioよりも優れた視覚/聴覚タスク性能
    *   テキストレベルのE2E音声命令追従

投稿者は、このPRが本物かどうかコミュニティに確認を求めています。

**要するに、この投稿は、テキスト、画像、音声、ビデオを理解し、テキストと音声を生成できる、新しいオープンソースのマルチモーダルモデル「Qwen2.5-Omni」が間もなく登場する可能性について議論しています。**

**2. このポストに対するコメントのうち、特に興味深いもの**

35 upvotesのコメント:

> Holy shit, Audio-Text-Video-Image to speech-Text.
> I just hope they'll have a larger scaled model, 7B is a bit small.

このコメントは、Qwen2.5-Omniのマルチモーダル能力に驚きを示しています。また、70億パラメータというモデルサイズが比較的小さいことに懸念を示し、より大規模なモデルの登場を期待しています。これは、大規模モデルが一般的に性能が高いため、当然の期待と言えるでしょう。

12 upvotesのコメント:

> I’ll say this having looked at the PR: this is a _lot_ of code to submit if they’re not planning on releasing it. HF Staff is in the mix too. I suspect we’ll get it in 6-8 weeks conservatively and 2-4 if they’re playing a hurry up game with the PR. Cool stuff. Wish I had time to write an OAI Realtime API adapter for it.

このコメントは、PRのコード量の多さから、Qwen2.5-Omniが実際にリリースされる可能性が高いと推測しています。また、Hugging Faceのスタッフが関与していることも、その可能性を高める要因として挙げています。リリース時期についても予測しており、現実的な期間を示唆しています。最後に、このモデルに対する期待と、それを利用したアプリケーション開発への意欲を示しています。

これらのコメントは、Qwen2.5-Omniに対する期待感と、その潜在的な応用可能性を示唆しており、特に興味深いと言えます。


---

# Gemma3 is outperforming a ton of models on fine-tuning / world knowledge

**Upvotes**: 39



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jhl6jp/gemma3_is_outperforming_a_ton_of_models_on/)

1.  **ポストの内容の説明:**

    このRedditの投稿は、GoogleのGemma3という新しいモデルが、ファインチューニングと知識評価において優れた性能を発揮しているという内容です。具体的には、以下の点が述べられています。

    *   **ファインチューニングでの性能:** OpenPipeという企業からのツイート（投稿に添付された画像を参照）によると、Gemma3はファインチューニングにおいて様々な評価指標で優れた結果を出しているようです。
    *   **知識評価での性能:** 12B（120億パラメータ）のGemma3モデルが、歴史上の学者たちの性別を識別するタスクにおいて、OpenAIのgpt-4o-miniよりも優れた性能を発揮しました。この評価ではファインチューニングは行われていません。
    *   **Prashanth Rao氏による分析:** 上記の知識評価の結果は、Prashanth Rao氏によって分析されたものです。（彼の簡単な紹介と、彼がBAMLコミュニティとKuzuDBに所属していることが記載されています。）
    *   **質問:** 投稿者は、他の人がGemma3を試してどのような結果が得られたかを知りたいと考えています。

    投稿全体として、Gemma3の初期評価が非常に有望であり、特にファインチューニングと特定の知識タスクにおいて優れた性能を示していることが強調されています。

2.  **特に興味深いコメント:**

    以下のコメントが特に興味深いと考えられます。

    *   **「We got two new models competing models simultaneously, gemma 3 and mistral small 3, I loved both gemma 2 and mistral small 2, they felt close on performance, but since mistral small was smaller it could fit my setup fully in GPU memory so I used it. It would be very useful if we see comparison for Gemma 3 and Mistral small 3, not just Gemma vs some other models and Mistral vs something other. It will be decisive battle for now.」**

        このコメントは、Gemma3とMistral small 3という二つの競合モデルが同時に登場したことに注目し、両者の直接的な比較を求めています。特に、Gemma 2とMistral small 2の比較において、GPUメモリの制約からMistral small 2を選んだ経験を共有しており、現実的な制約を考慮した上でのモデル選択の重要性を示唆しています。Gemma3とMistral small 3の比較が今後の競争を左右する可能性があるという意見も興味深いです。


---

# Fallen Gemma3 4B 12B 27B - An unholy trinity with no positivity! For users, mergers and cooks!

**Upvotes**: 105



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jhdpjk/fallen_gemma3_4b_12b_27b_an_unholy_trinity_with/)

1.  **ポストの内容の説明**

このRedditのポストは、TheDrummerというユーザーが公開した、Gemma 3という大規模言語モデル（LLM）をファインチューニングした3つのモデル（4B, 12B, 27B）に関するものです。タイトルから推測するに、これらのモデルは「ポジティブさを排除」するように調整されており、投稿文には「完全な検閲解除ではないが、ポジティブさはなくなるはず」と書かれています。また、ビジョン（画像認識）機能が動作することも示唆されています。Hugging Faceへのリンクが提供されており、ユーザーはこれらのモデルをダウンロードして試すことができます。このモデルは、ユーザー、モデルのマージを行う人、そして「cooks」（モデルを調理する人、つまりファインチューニングや調整を行う人）を対象としているようです。

2.  **興味深いコメント**

いくつかのコメントが興味深いです。

*   **ベンチマークに関する質問:** モデルの性能をオリジナルと比較するベンチマークを実行しているかどうかを尋ねるコメントは、ファインチューニングによる性能の変化（損失または向上）に関心があることを示しています。これは、モデルの品質を客観的に評価する上で重要な質問です。

*   **知性とアシスタントシステムプロンプトに関するコメント:** このモデルが非常に知的であり、デフォルトのアシスタントシステムプロンプトにおいて大胆であるという評価は、モデルの性格設定や応答の傾向を示唆しており、ユーザーがどのようにモデルを活用するかを考える上で役立ちます。

*   **毒性/支配的なキャラクターに関する注意:** モデルに毒性や支配的なキャラクターを与えるとどうなるか注意するよう促すコメントは、モデルの倫理的な側面や、意図しない挙動を引き出す可能性について注意を喚起しています。

*   **「クレイジーで面白い」「完全に狂っている」というコメント:** これは、モデルの出力が予測不可能で、時には奇妙なものであることを示唆しています。しかし、それでも「ほとんど一貫性がある」という評価は、モデルが完全に破綻しているわけではないことを意味しています。これは、特定の用途（例えば、クリエイティブな文章作成やエンターテイメント）において、このモデルが有用である可能性を示唆しています。


---

# Has anyone switched from remote models (claude, etc.) models to local? Meaning did your investment pay off?

**Upvotes**: 65



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jhf6x3/has_anyone_switched_from_remote_models_claude_etc/)

はい、承知いたしました。以下に、ご質問への回答を順を追って説明します。

**1. このポストの内容の説明**

このRedditのポストは、大規模言語モデル（LLM）の使用方法に関する議論を提起しています。具体的には、以下の点について意見交換がされています。

*   **リモートモデル（API経由で使用するクラウド上のモデル、例：Claudeなど）からローカルモデル（自分のコンピューターで動作させるモデル）への移行は、投資に見合うか？**
    *   投稿者は、API利用料が高額になる場合があるため、ローカルモデルの方が安価になる可能性があるのではないかと問題提起しています。（特に、Claude APIを1日に10〜30ドル以上使うユーザーにとっては。）
    *   ただし、ローカルモデルの性能はAPIモデルに劣る可能性があることも認識しています。

**2. このポストに対するコメントのうち、特に興味深いもの**

以下の3つのコメントが特に興味深いと考えられます。

*   **32 upvotesのコメント:**
    *   皮肉を込めて、ローカルモデルの計算時に発生する熱を暖房や給湯に利用すれば、実質的に無料でLLMを利用できると述べています。
    *   真面目な意見としては、一般的には電気代を考慮するとローカルモデルの方が安価になるとは限らないとしています。API利用料は月10ドル以下に抑えられる場合もあるからです。
    *   ただし、プライバシーと独立性を重視する立場から、クラウドLLMの使用をできるだけ避けたいという意見を述べています。このコメントは、コストだけでなく、別の重要な観点（プライバシー）を提起している点が興味深いです。

*   **26 upvotesのコメント:**
    *   ローカルモデルを使用するのは、費用対効果だけでなく、「できるからやっている」という純粋な興味に基づいているという意見です。これは、技術的な探求心や趣味としての側面を示唆しており、興味深い視点です。

*   **34 upvotesのコメント:**
    *   特定の用途（記事のスクレイピングと情報収集の要約）においては、ローカルモデルが費用対効果が高いと述べています。
    *   ただし、複雑なタスクには依然としてAPIモデル（O3 miniなど）を使用していると述べています。これは、タスクの種類によってローカルモデルとAPIモデルを使い分けるという、現実的な運用方法を示唆しており、参考になります。


---

# Are any of the big API providers (OpenAI, Anthropic, etc) actually making money, or are all of them operating at a loss and burning through investment cash?

**Upvotes**: 17



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jhl6y0/are_any_of_the_big_api_providers_openai_anthropic/)

1.  **ポストの内容の説明**

このRedditの投稿は、大規模言語モデル（LLM）を提供する企業（OpenAI、Anthropicなど）が実際に利益を上げているのか、それとも投資資金を使い果たしながら赤字経営をしているのかという疑問を提起しています。

投稿者は、現状ではローカルでLLMを動かすよりも、APIを利用する方がハードウェアへの投資やエネルギーコストなどを考慮すると安価であるという認識が一般的であると述べています。しかし、APIの低価格は長期的に持続可能かどうか疑問を呈しています。

ローカルでLLMを動かす理由は、プライバシー、独立性、趣味、カスタマイズ、オフラインでの作業、あるいは単に自分のGPUと会話できることへの驚きなどが挙げられています。

投稿者は、LLMプロバイダーがこれまでに利益を上げているという情報を知らないため、APIの価格設定が投資資金の枯渇後にどのように変化するのか、ローカル環境がAPIよりも安価になる可能性について考察しています。つまり、現状のAPI価格は、投資資金に支えられた一時的なものではないかという懸念を示唆しています。

2.  **特に興味深いコメント**

*   **OpenAIは赤字だが、モデルを開発せずにホストのみを行うプロバイダーは利益を出している可能性があるというコメント:** これは、LLMビジネスの構造に焦点を当てています。モデル開発には莫大なコストがかかるため、OpenAIのような企業は赤字になっている可能性がある一方、OpenRouterのように既存のモデルをホストするだけの企業は、より少ないコストで利益を上げられる可能性があるという指摘は、ビジネスモデルの違いを理解する上で重要です。

*   **NovelAIは投資資金なしで利益を上げている可能性があるというコメント:** NovelAIは独自のモデルを開発し、ホストも行っていますが、投資資金に頼っていません。サービスを改善し続けていることから、利益を上げていると推測されています。このコメントは、投資資金に頼らずとも、独自の戦略でLLMビジネスを成功させることができる可能性を示唆しています。

*   **業界リーダーはコストを大幅に削減する最適化技術を持っている可能性があるというコメント:** 大手企業は、一般の人が利用できない高度な最適化技術を持っている可能性があり、それが低コストでのサービス提供を可能にしているかもしれないという指摘です。これは、表面的な価格だけでは判断できない、技術力の差がコストに影響を与えている可能性を示唆しています。


---

# LLama.cpp smillar speed but in pure Rust, local LLM inference alternatives.

**Upvotes**: 147



[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jh4s2h/llamacpp_smillar_speed_but_in_pure_rust_local_llm/)

1.  **ポストの内容の説明:**

このRedditのポストは、ローカル環境でLLM（大規模言語モデル）を推論するための新しい選択肢を紹介しています。これまでの主な選択肢はllama.cppのようなC++ベースのツールでしたが、設定が難しく、新しいモデルへの対応もコミュニティの助けが必要でした。

このポストの作成者は、Rustで書かれた「Crane」という新しいフレームワークを提案しています。Craneは、llama.cppと同等の速度でLLMを推論できると主張しており、PyTorchよりも高速です。特に、C++を必要とせず、Rustで開発されている点が特徴です。また、PyO3を使ってPythonから呼び出すことも可能です。

具体的には、llama.cppのチャットCLIのような最小限の例を作成し、Candleフレームワークをベースに、PyTorchよりも6倍高速に動作すると述べています。

今後の計画として、Spark-TTSやOrpheus-TTSのサポートを追加したいと考えており、Rustと高速推論に興味のある開発者に対して、協力してくれるよう呼びかけています。

2.  **特に興味深いコメント:**

*   **「Please provide some benchmarks against llamacpp.」** (54 upvotes): このコメントは、Craneの速度性能をllama.cppと比較して明確に示してほしいという要望を表しています。llama.cppがローカルLLM推論の事実上の標準となっているため、Craneが本当に「similar speed」であるかどうかを知りたいというユーザーの関心の高さを示しています。ベンチマークは、Craneの競争力を評価するために不可欠な情報です。

*   **「35 t/s for a 0.5b model is not "similar speed" and if it was there would be a comparison to llama.cpp instead of PyTorch.」** (62 upvotes): このコメントは、Craneの速度性能に対する疑問を表明しています。0.5B（5億パラメータ）のモデルで35トークン/秒という速度は、「similar speed」とは言えないと指摘しています。また、llama.cppとの比較ではなく、PyTorchとの比較になっている点も、Craneの性能に対する疑念を深める要因となっています。このコメントは、ポストの主張に対する批判的な視点を提供しています。

*   **「So is it like mistralrs? https://github.com/EricLBuehler/mistral.rs
BTW a tiny little 0.5b should get a lot more tk/s than 35 on a m1?」** (36 upvotes): このコメントは、Craneがmistral.rsのようなプロジェクトであるかどうかを尋ねています。これは、Rustで書かれた他のLLM推論フレームワークとの類似性を探るものです。また、0.5Bモデルで35トークン/秒という速度がM1チップで期待されるよりも遅いのではないかと指摘しています。このコメントは、Craneの技術的な位置づけと、ハードウェア性能に対する最適化の可能性について疑問を投げかけています。


---

# Token impact by long-Chain-of-Thought Reasoning Models

**Upvotes**: 46

![Image](https://i.redd.it/hxrz73n2l9qe1.png)

[View on Reddit](https://www.reddit.com/r/LocalLLaMA/comments/1jhbxr9/token_impact_by_longchainofthought_reasoning/)

はい、承知いたしました。順を追って詳細に、分かりやすく回答いたします。

**1. このポストの内容の説明**

このRedditのポストは、Chain-of-Thought Reasoning（CoT、連鎖的思考推論）モデルという種類のAIモデルにおける「トークン」の使用状況に関するものです。

*   **トークン（Token）とは：** ここでは、AIモデルがテキストを処理する際の基本的な単位を指します。単語や文字の一部などがトークンとして扱われます。モデルが生成するテキストの長さや複雑さを測る上で、トークンの数が重要な指標となります。

*   **Chain-of-Thought Reasoning（CoT）モデルとは：** これは、AIが段階的に思考プロセスを明らかにし、推論過程を示すことで、より複雑な問題を解決するアプローチです。従来のAIモデルよりも、人間のように「考えながら」答えを出すことが特徴です。

*   **ポストの概要：**
    *   投稿者は、様々なCoTモデル（ローカルモデルとそうでないモデルを含む）に対して、ベンチマークテストを実施しました。
    *   約250のクエリ（質問）を各モデルに与え、モデルが生成するトークン数を計測・分析しました。
    *   主な分析ポイントは以下の3点です。
        *   **Output TOK Rate (出力トークン率):** 従来のCoTを使用しないモデルと比較して、CoTモデルが出力する総トークン数。
        *   **vs FinalReply:** CoTモデルが推論過程で使用した総トークン数と、最終的な回答で使用したトークン数の比較。
        *   **TOK Distribution (トークン分布):** モデルが使用したトークン全体に占める、推論過程で使用されたトークンの割合。
    *   投稿者は、これらのデータをまとめた詳細なレポートへのリンクを提供しています。
    *   投稿者は、このデータはあくまで全体的な傾向を示すものであり、個々のクエリの内容によって結果が大きく変動する可能性があることを注意喚起しています。

**2. このポストに対するコメントのうち、特に興味深いもの**

コメントのうち、特に興味深いのは以下の2つです。

*   **「It usually varies a lot with the task what kind of task was used on this?」** (どんなタスクを使ったのかでかなり変わってくると思いますが、どんな種類のタスクを使いましたか？)
    *   このコメントは、CoTモデルのトークン使用量とタスクの種類が密接に関係している点を指摘しています。タスクの難易度や性質（例：算数、常識推論、創造的な文章作成）によって、モデルの思考プロセスが異なり、結果としてトークン使用量も大きく変動する可能性があります。このコメントは、投稿者のデータ解釈に重要なコンテキストを提供しており、データの一般化可能性に注意を促しています。

*   **「How did they measure it for OpenAI o\*? Do they have access to their raw reasoning tokens?」** (OpenAIのモデルではどのように測定したのですか？ 彼らは生の推論トークンにアクセスできるのですか？)
    *   OpenAIのようなAPIを通じて利用できるモデル（例：GPT-3, GPT-4）の場合、内部の推論過程のトークン数を直接計測することは困難です。このコメントは、投稿者がどのようにしてOpenAIモデルの推論トークン数を推定・計測したのかという方法論的な疑問を提起しています。もし、何らかの推定方法を用いている場合、その精度が結果に影響を与える可能性があります。このコメントは、データの信頼性に関する重要なポイントを指摘しています。

これらのコメントは、投稿されたデータの解釈を深め、その限界を理解する上で非常に有益です。

